#!/usr/bin/env python
# vim: filetype=python

'''Script for training the model'''
import time
import os
import numpy as np
import tensorflow as tf
from deepsphinx.seq2seq_model import seq2seq_model
from deepsphinx.data import read_data_queue, get_speaker_stats
from deepsphinx.vocab import VOCAB
from deepsphinx.utils import wer, FLAGS
from deepsphinx.flags import load_flags
try:
    import pywrapfst as fst
except ImportError:
    pass


#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.7)

def run_eval(graph,
             queue1,
             queue2,
             queue3,
             queue4,
             queue_, 
             predictions,
             outputs,
             output_lengths,
             step,
             cost,
             keep_prob_tensor,
             mean_speaker,
             var_speaker,
             pred_scores,
             lm_fst,
             training_mode_tensor):
    '''Evaluate with eval dataset'''

    tf.logging.info('Evaluation started')
    with graph.as_default():
        writer = tf.summary.FileWriter(FLAGS.job_dir)
        tf.Session.reset(None, ['queue1'])
        tf.Session.reset(None, ['queue2'])
        tf.Session.reset(None, ['queue3'])
        tf.Session.reset(None, ['queue4'])
        tf.Session.reset(None, ['queue_'])
        with tf.Session() as sess:
            tf.train.Saver().restore(sess, FLAGS.checkpoint_path)
            read_data_queue('eval',
                            queue1,
                            queue2,
                            queue3,
                            queue4,
                            queue_,
                            sess,
                            mean_speaker,
                            var_speaker,
                            lm_fst)
            tot_wer = 0.0
            tot_cer = 0.0
            batch_loss = 0.0
            tot_ev = 0
            tot_bat = 0
            count = 0
            coord = tf.train.Coordinator(
                clean_stop_exception_types=(
                    tf.errors.CancelledError,
                    tf.errors.OutOfRangeError))

            with coord.stop_on_exception():
                while not coord.should_stop():
                    pred, _, out, out_len, loss = sess.run(
                        [predictions, pred_scores, outputs, output_lengths, cost],
                        feed_dict={keep_prob_tensor: 1.0, training_mode_tensor: True})
                    tot_ev += pred.shape[0]
                    tot_bat += 1
                    batch_loss += loss 
                    count += 1
                    for i in range(pred.shape[0]):
                        best_wer = 100.0
                        best_cer = 100.0
                        for j in range(FLAGS.best_n_inference):
                            real_out = ''.join([VOCAB[l]
                                                for l in out[i, :out_len[i] - 1]])
                            pred_out = ''.join([VOCAB[l]
                                                for l in pred[i, :, j]])
                            pred_out = pred_out.split('<')[0]
                            cur_wer = wer(real_out.split(), pred_out.split())
                            # tf.logging.info('{} : {}'.format(pred_out, sc[i, j]))
                            best_wer = min(best_wer, cur_wer)
                            best_cer = min(best_cer, wer(
                                list(real_out), list(pred_out)))
                        tot_wer += best_wer
                        tot_cer += best_cer

            if tot_ev > 0:
                tf.logging.info('WER: {}, CER: {}'.format(
                    tot_wer / tot_ev, tot_cer / tot_ev))
                tf.logging.info('Total Loss: {}'.format(batch_loss))
                summary = tf.Summary(
                    value=[tf.Summary.Value(tag='WER_valid', simple_value=tot_wer / tot_ev),
                           tf.Summary.Value(tag='CER_valid', simple_value=tot_cer / tot_ev),
                           tf.Summary.Value(tag='loss_valid', simple_value=batch_loss / tot_bat)
                          ])
                writer.add_summary(summary, global_step=sess.run(step))
                writer.flush()
            coord.request_stop()
    tf.logging.info('Evaluation finished')


def train(_):
    '''Train the model and evaluate at every epoch'''

    checkpoint = os.path.join(FLAGS.job_dir, 'checkpoints/')

    if FLAGS.eval_only:
        sets = ['eval']
    else:
        sets = ['eval', 'train']

    if FLAGS.use_train_lm or FLAGS.use_inference_lm:
        lm_fst = fst.Fst.read_from_string(tf.gfile.FastGFile(FLAGS.fst_path, 'rb').read())
    else:
        lm_fst = None

    graph = tf.Graph()
    with graph.as_default():
        learning_rate_tensor = tf.placeholder(
            tf.float32,
            name='learning_rate')
        keep_prob_tensor = tf.placeholder(
            tf.float32,
            name='keep_prob')
        training_mode_tensor = tf.placeholder(
            tf.bool,
            name='training_mode')
        l_param = tf.placeholder(
            tf.float32,
            name='l_param')

        # https://stackoverflow.com/questions/39204335/can-a-tensorflow-queue-be-reopened-after-it-is-closed
        with tf.container('queue'):
            queue1 = tf.PaddingFIFOQueue(
                capacity=64,
                dtypes=['float32', 'int32', 'int32', 'int32'],
                shapes=[[None, FLAGS.nfilt * 3 + 1], [], [None], []],
                name='feed_queue1')
            
            queue2 = tf.PaddingFIFOQueue(
                capacity=64,
                dtypes=['float32', 'int32', 'int32', 'int32'],
                shapes=[[None, FLAGS.nfilt * 3 + 1], [], [None], []],
                name='feed_queue2')
         
            queue3 = tf.PaddingFIFOQueue(
                capacity=64,
                dtypes=['float32', 'int32', 'int32', 'int32'],
                shapes=[[None, FLAGS.nfilt * 3 + 1], [], [None], []],
                name='feed_queue3')

            queue4 = tf.PaddingFIFOQueue(
                capacity=64,
                dtypes=['float32', 'int32', 'int32', 'int32'],
                shapes=[[None, FLAGS.nfilt * 3 + 1], [], [None], []],
                name='feed_queue4')

            
            queue_ = tf.PaddingFIFOQueue(
                capacity=64,
                dtypes=['float32', 'int32', 'int32', 'int32'],
                shapes=[[None, FLAGS.nfilt * 3 + 1], [], [None], []],
                name='feed_queue_')

          

            inputs1, input_lengths1, outputs1, output_lengths1 = queue1.dequeue_many(
                FLAGS.batch_size)
            inputs2, input_lengths2, outputs2, output_lengths2 = queue2.dequeue_many(
                FLAGS.batch_size)
            inputs3, input_lengths3, outputs3, output_lengths3 = queue3.dequeue_many(
                FLAGS.batch_size)
            inputs4, input_lengths4, outputs4, output_lengths4 = queue4.dequeue_many(
                FLAGS.batch_size)
            
            inputs_, input_lengths_, outputs_, output_lengths_ = queue_.dequeue_many(
                FLAGS.batch_size)
            

            
            input_lengths_t = tf.concat([input_lengths1, input_lengths2, input_lengths3, input_lengths4,input_lengths_],0)
            output_lengths = tf.concat([output_lengths1, output_lengths2, output_lengths3, output_lengths4],0)
            
            i_size = tf.reduce_max(input_lengths_t)
            o_shape = tf.reduce_max(output_lengths)

            pad_shape1 = tf.stack([FLAGS.batch_size,i_size-tf.shape(inputs1)[1],FLAGS.nfilt*3+1])    
            pad_shape2 = tf.stack([FLAGS.batch_size,i_size-tf.shape(inputs2)[1],FLAGS.nfilt*3+1])    
            pad_shape3 = tf.stack([FLAGS.batch_size,i_size-tf.shape(inputs3)[1],FLAGS.nfilt*3+1])    
            pad_shape4 = tf.stack([FLAGS.batch_size,i_size-tf.shape(inputs4)[1],FLAGS.nfilt*3+1])    
            pad_shape_d = tf.stack([FLAGS.batch_size,i_size-tf.shape(inputs_)[1],FLAGS.nfilt*3+1])    
            pad_shape_o1 = tf.stack([FLAGS.batch_size,o_shape - tf.shape(outputs1)[1]])
            pad_shape_o2 = tf.stack([FLAGS.batch_size,o_shape - tf.shape(outputs2)[1]])
            pad_shape_o3 = tf.stack([FLAGS.batch_size,o_shape - tf.shape(outputs3)[1]])
            pad_shape_o4 = tf.stack([FLAGS.batch_size,o_shape - tf.shape(outputs4)[1]])

            zeros_o1 = tf.fill(pad_shape_o1,0)
            zeros_o2 = tf.fill(pad_shape_o2,0)
            zeros_o3 = tf.fill(pad_shape_o3,0)
            zeros_o4 = tf.fill(pad_shape_o4,0)

            zeros1 = tf.fill(pad_shape1,0.0)
            zeros2 = tf.fill(pad_shape2,0.0)
            zeros3 = tf.fill(pad_shape3,0.0)
            zeros4 = tf.fill(pad_shape4,0.0)
            zeros_d = tf.fill(pad_shape_d,0.0)

            inputs_1p = tf.concat([inputs1,zeros1],1)
            inputs_2p = tf.concat([inputs2,zeros2],1)
            inputs_3p = tf.concat([inputs3,zeros3],1)
            inputs_4p = tf.concat([inputs4,zeros4],1)
            inputs_d = tf.concat([inputs_,zeros_d],1)

            outputs_1p = tf.concat([outputs1,zeros_o1],1)
            outputs_2p = tf.concat([outputs2,zeros_o2],1)
            outputs_3p = tf.concat([outputs3,zeros_o3],1)
            outputs_4p = tf.concat([outputs4,zeros_o4],1)

            inputs_t = tf.concat([inputs_1p, inputs_2p, inputs_3p, inputs_4p,inputs_d],0)
            #input_lengths_t = tf.concat([input_lengths1, input_lengths2, input_lengths3, input_lengths4,input_lengths_],0)
            outputs = tf.concat([outputs_1p, outputs_2p, outputs_3p, outputs_4p],0)
            #output_lengths = tf.concat([output_lengths1, output_lengths2, output_lengths3, output_lengths4],0)


	
        training_logits, predictions, train_op, cost, step, pred_scores, loss_d = seq2seq_model(
            inputs_t,
            outputs,
            input_lengths_t,
            output_lengths,
            lm_fst,
            keep_prob_tensor,
            training_mode_tensor,
            l_param)

        writer = tf.summary.FileWriter(FLAGS.job_dir)
        saver = tf.train.Saver()
        batch_loss = 0.0
        writer.add_graph(graph)

        mean_speaker, var_speaker = get_speaker_stats(sets)
        tf.logging.info('Starting training')

        for epoch_i in range(1, FLAGS.num_epochs + 1):
            if (FLAGS.checkpoint_path is not None):
                run_eval(graph,
                         queue1,
                         queue2,
                         queue3,
                         queue4,
                         queue_,
                         predictions,
                         outputs,
                         output_lengths,
                         step,
                         cost,
                         keep_prob_tensor,
                         mean_speaker,
                         var_speaker,
                         pred_scores,
                         lm_fst,
                         training_mode_tensor)
            if FLAGS.eval_only:
                break
            tf.Session.reset(None, ['queue1'])
            tf.Session.reset(None, ['queue2'])
            tf.Session.reset(None, ['queue3'])
            tf.Session.reset(None, ['queue4'])
            tf.Session.reset(None, ['queue_'])	
            with tf.Session() as sess:
                coord = tf.train.Coordinator(
                    clean_stop_exception_types=(
                        tf.errors.CancelledError,
                        tf.errors.OutOfRangeError))
                if (FLAGS.checkpoint_path is None):
                    sess.run(tf.global_variables_initializer())
                    sess.run(tf.local_variables_initializer())
                    last_display_step = 0
                else:
                    saver.restore(sess, FLAGS.checkpoint_path)
                    last_display_step = sess.run(step)

                read_data_queue('train',
                                queue1,
                                queue2,
                                queue3,
                                queue4,
                                queue_,						
                                sess,
                                mean_speaker,
                                var_speaker,
                                lm_fst)

                #temp = sess.run(input_lengths)
                #print(temp)     

                with coord.stop_on_exception():
                    while not coord.should_stop():
                        start_time = time.time()

                        loss, _, batch_i, loss_dom = sess.run(
                            [cost, train_op, step, loss_d],
                            feed_dict={learning_rate_tensor: FLAGS.learning_rate,
                                       l_param: 0.5,
                                       training_mode_tensor: True,
                                       keep_prob_tensor: FLAGS.keep_prob})
                        
                        batch_loss += loss
                        end_time = time.time()
                        batch_time = end_time - start_time

                        if batch_i % FLAGS.display_step == 0 and batch_i - last_display_step > 0:
                            tf.logging.info('Epoch {:>3}/{} Batch {:>4} - Loss: {:>6.3f}, Seconds: {:>4.2f}'
                                            .format(epoch_i,
                                                    FLAGS.num_epochs,
                                                    batch_i,
                                                    batch_loss / (batch_i - last_display_step),
                                                    batch_time))

                            tf.logging.info('Domain class loss:{}'.format(loss_d))
                            tot_wer = 0.0
                            tot_cer = 0.0

                            pred, out, out_len = sess.run(
                                [predictions, outputs, output_lengths],
                                feed_dict={keep_prob_tensor: 1.0, training_mode_tensor: True})
                            for i in range(pred.shape[0]):
                                real_out = ''.join(
                                    [VOCAB[l] for l in out[i, :out_len[i] - 1]])
                                pred_out = ''.join([VOCAB[l]
                                                    for l in pred[i, :, 0]])
                                pred_out = pred_out.split('<')[0]
                                tot_wer += wer(real_out.split(),
                                               pred_out.split())
                                tot_cer += wer(list(real_out), list(pred_out))
                            tf.logging.info(
                                'Sample real output: {}'.format(real_out))
                            tf.logging.info(
                                'Sample predicted output: {}'.format(pred_out))
                            tf.logging.info('WER: {}, CER: {}'.format(
                                tot_wer / pred.shape[0], tot_cer / pred.shape[0]))
                            summary = tf.Summary(
                                value=[tf.Summary.Value(
                                    tag='WER', simple_value=tot_wer / pred.shape[0]),
                                       tf.Summary.Value(
                                           tag='CER', simple_value=tot_cer / pred.shape[0]),
                                       tf.Summary.Value(
                                           tag='loss',
                                           simple_value=batch_loss / (batch_i - last_display_step))
                                      ])
                            last_display_step = batch_i
                            writer.add_summary(summary, global_step=batch_i)
                            writer.flush()
                            batch_loss = 0.0

                        # Reduce learning rate, but not below its minimum value
                        FLAGS.learning_rate *= FLAGS.learning_rate_decay
                        if FLAGS.learning_rate < FLAGS.min_learning_rate:
                            FLAGS.learning_rate = FLAGS.min_learning_rate

                tf.logging.info('Epoch completed, saving')
                FLAGS.checkpoint_path = saver.save(
                    sess, checkpoint + 'batch', step)

                #queue.close()
                #queue_close()
                coord.request_stop()


if __name__ == '__main__':
    tf.logging.set_verbosity(tf.logging.INFO)
    load_flags()
    tf.app.run(train)
